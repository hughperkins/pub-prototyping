test_reinf_grad1.py. 06174e6
iteration 0 avg_reward 0.21
iteration 100 avg_reward 14.02
iteration 200 avg_reward 14.93
iteration 300 avg_reward 14.45
iteration 400 avg_reward 15.7
iteration 500 avg_reward 14.98
iteration 600 avg_reward 15.66
iteration 700 avg_reward 15.59
iteration 800 avg_reward 16.3
iteration 900 avg_reward 15.62
iteration 1000 avg_reward 17.07
iteration 1100 avg_reward 16.38
iteration 1200 avg_reward 18.54
iteration 1300 avg_reward 18.54
iteration 1400 avg_reward 18.34
iteration 1500 avg_reward 21.43
iteration 1600 avg_reward 21.52
iteration 1700 avg_reward 23.79
iteration 1800 avg_reward 24.8
iteration 1900 avg_reward 25.48
iteration 2000 avg_reward 26.26
iteration 2100 avg_reward 28.71
iteration 2200 avg_reward 33.1
iteration 2300 avg_reward 32.23
iteration 2400 avg_reward 36.21
iteration 2500 avg_reward 36.12
iteration 2600 avg_reward 37.14
iteration 2700 avg_reward 40.64
iteration 2800 avg_reward 44.96
iteration 2900 avg_reward 44.61
iteration 3000 avg_reward 49.15
iteration 3100 avg_reward 48.26
iteration 3200 avg_reward 50.22
iteration 3300 avg_reward 57.23
iteration 3400 avg_reward 57.13
iteration 3500 avg_reward 49.68
iteration 3600 avg_reward 61.0
iteration 3700 avg_reward 58.73
iteration 3800 avg_reward 63.31
iteration 3900 avg_reward 61.37
iteration 4000 avg_reward 73.96
iteration 4100 avg_reward 72.91
iteration 4200 avg_reward 81.74
iteration 4300 avg_reward 77.76
iteration 4400 avg_reward 74.87
iteration 4500 avg_reward 86.81
iteration 4600 avg_reward 96.67
iteration 4700 avg_reward 96.64
iteration 4800 avg_reward 105.66
iteration 4900 avg_reward 117.14
iteration 5000 avg_reward 123.0
iteration 5100 avg_reward 125.29
iteration 5200 avg_reward 140.23
iteration 5300 avg_reward 135.99
iteration 5400 avg_reward 144.91
iteration 5500 avg_reward 135.75
iteration 5600 avg_reward 146.84
iteration 5700 avg_reward 148.1
iteration 5800 avg_reward 149.32
iteration 5900 avg_reward 150.45
iteration 6000 avg_reward 149.86
iteration 6100 avg_reward 155.09
iteration 6200 avg_reward 155.63
iteration 6300 avg_reward 158.0
iteration 6400 avg_reward 148.31
iteration 6500 avg_reward 154.9
iteration 6600 avg_reward 168.47
iteration 6700 avg_reward 164.96
iteration 6800 avg_reward 158.06
iteration 6900 avg_reward 164.61
iteration 7000 avg_reward 170.72
iteration 7100 avg_reward 164.73
iteration 7200 avg_reward 165.67
iteration 7300 avg_reward 173.45
iteration 7400 avg_reward 172.47
iteration 7500 avg_reward 170.59
iteration 7600 avg_reward 172.16
iteration 7700 avg_reward 177.64
iteration 7800 avg_reward 173.9
iteration 7900 avg_reward 169.65
iteration 8000 avg_reward 169.9
iteration 8100 avg_reward 175.14
iteration 8200 avg_reward 164.57
iteration 8300 avg_reward 182.06
iteration 8400 avg_reward 172.76
iteration 8500 avg_reward 175.18
iteration 8600 avg_reward 174.11
iteration 8700 avg_reward 179.23
iteration 8800 avg_reward 181.01
iteration 8900 avg_reward 181.23
iteration 9000 avg_reward 181.91
iteration 9100 avg_reward 177.36
iteration 9200 avg_reward 183.97
iteration 9300 avg_reward 179.03
iteration 9400 avg_reward 184.09
iteration 9500 avg_reward 183.78
iteration 9600 avg_reward 191.24
iteration 9700 avg_reward 182.38
iteration 9800 avg_reward 181.4

Using test_reinf_qsa.py 24aecaf :
```
iteration 0 avg_reward 0.1 loss 
 9.9945
[torch.FloatTensor of size 1]

iteration 100 avg_reward 9.97 loss 
 2475.8872
[torch.FloatTensor of size 1]

iteration 200 avg_reward 9.8 loss 
 4842.8989
[torch.FloatTensor of size 1]

iteration 300 avg_reward 9.77 loss 
 6154.5542
[torch.FloatTensor of size 1]

iteration 400 avg_reward 10.04 loss 
 7014.6445
[torch.FloatTensor of size 1]

iteration 500 avg_reward 10.07 loss 
 7656.6763
[torch.FloatTensor of size 1]

iteration 600 avg_reward 10.15 loss 
 8123.7446
[torch.FloatTensor of size 1]

iteration 700 avg_reward 10.07 loss 
 8380.0625
[torch.FloatTensor of size 1]

iteration 800 avg_reward 9.75 loss 
 8489.8398
[torch.FloatTensor of size 1]

iteration 900 avg_reward 9.83 loss 
 8540.7412
[torch.FloatTensor of size 1]

iteration 1000 avg_reward 9.94 loss 
 8612.9199
[torch.FloatTensor of size 1]

iteration 1100 avg_reward 10.11 loss 
 8772.7021
[torch.FloatTensor of size 1]

iteration 1200 avg_reward 9.91 loss 
 8803.7607
[torch.FloatTensor of size 1]

iteration 1300 avg_reward 9.76 loss 
 8770.7148
[torch.FloatTensor of size 1]

iteration 1400 avg_reward 9.86 loss 
 8729.6602
[torch.FloatTensor of size 1]

iteration 1500 avg_reward 9.91 loss 
 8756.3711
[torch.FloatTensor of size 1]

iteration 1600 avg_reward 9.9 loss 
 8797.9990
[torch.FloatTensor of size 1]

iteration 1700 avg_reward 9.92 loss 
 8807.1797
[torch.FloatTensor of size 1]

iteration 1800 avg_reward 9.84 loss 
 8792.4023
[torch.FloatTensor of size 1]

iteration 1900 avg_reward 9.79 loss 
 8752.7842
[torch.FloatTensor of size 1]

iteration 2000 avg_reward 10.04 loss 
 8797.9473
[torch.FloatTensor of size 1]

iteration 2100 avg_reward 10.17 loss 
 8905.6719
[torch.FloatTensor of size 1]

iteration 2200 avg_reward 10.29 loss 
 9083.9678
[torch.FloatTensor of size 1]

iteration 2300 avg_reward 10.36 loss 
 9206.5479
[torch.FloatTensor of size 1]

iteration 2400 avg_reward 10.36 loss 
 9300.2500
[torch.FloatTensor of size 1]

iteration 2500 avg_reward 10.64 loss 
 9599.1299
[torch.FloatTensor of size 1]

iteration 2600 avg_reward 10.25 loss 
 9604.8398
[torch.FloatTensor of size 1]

iteration 2700 avg_reward 10.54 loss 
 9637.4219
[torch.FloatTensor of size 1]

iteration 2800 avg_reward 10.53 loss 
 9799.4980
[torch.FloatTensor of size 1]

iteration 2900 avg_reward 10.77 loss 
 9911.1992
[torch.FloatTensor of size 1]

iteration 3000 avg_reward 10.81 loss 
 10116.2930
[torch.FloatTensor of size 1]

iteration 3100 avg_reward 10.68 loss 
 10148.0977
[torch.FloatTensor of size 1]

iteration 3200 avg_reward 11.37 loss 
 10430.7217
[torch.FloatTensor of size 1]

iteration 3300 avg_reward 11.96 loss 
 11029.1621
[torch.FloatTensor of size 1]

iteration 3400 avg_reward 11.32 loss 
 11338.2988
[torch.FloatTensor of size 1]

iteration 3500 avg_reward 11.39 loss 
 11414.6133
[torch.FloatTensor of size 1]

iteration 3600 avg_reward 11.86 loss 
 11718.1387
[torch.FloatTensor of size 1]

iteration 3700 avg_reward 11.98 loss 
 12085.5039
[torch.FloatTensor of size 1]

iteration 3800 avg_reward 11.47 loss 
 12084.2852
[torch.FloatTensor of size 1]

iteration 3900 avg_reward 12.48 loss 
 12407.9639
[torch.FloatTensor of size 1]

iteration 4000 avg_reward 12.22 loss 
 12906.5400
[torch.FloatTensor of size 1]

iteration 4100 avg_reward 10.87 loss 
 12549.6797
[torch.FloatTensor of size 1]

iteration 4200 avg_reward 10.21 loss 
 11858.9707
[torch.FloatTensor of size 1]

iteration 4300 avg_reward 9.88 loss 
 11156.4199
[torch.FloatTensor of size 1]

iteration 4400 avg_reward 10.02 loss 
 10627.2695
[torch.FloatTensor of size 1]

iteration 4500 avg_reward 9.82 loss 
 10154.0654
[torch.FloatTensor of size 1]

iteration 4600 avg_reward 10.03 loss 
 9845.9551
[torch.FloatTensor of size 1]

iteration 4700 avg_reward 9.86 loss 
 9592.1104
[torch.FloatTensor of size 1]

iteration 4800 avg_reward 9.7 loss 
 9340.4014
[torch.FloatTensor of size 1]

iteration 4900 avg_reward 9.96 loss 
 9158.9854
[torch.FloatTensor of size 1]

iteration 5000 avg_reward 10.0 loss 
 9119.7031
[torch.FloatTensor of size 1]

iteration 5100 avg_reward 9.86 loss 
 9025.4082
[torch.FloatTensor of size 1]

iteration 5200 avg_reward 9.81 loss 
 8967.7021
[torch.FloatTensor of size 1]

iteration 5300 avg_reward 9.86 loss 
 8898.5508
[torch.FloatTensor of size 1]

iteration 5400 avg_reward 10.0 loss 
 7193.8208
[torch.FloatTensor of size 1]

iteration 5500 avg_reward 10.02 loss 
 4815.3467
[torch.FloatTensor of size 1]

iteration 5600 avg_reward 9.95 loss 
 3931.0061
[torch.FloatTensor of size 1]

iteration 5700 avg_reward 26.85 loss 
 18044.2891
[torch.FloatTensor of size 1]

iteration 5800 avg_reward 22.07 loss 
 27439.7754
[torch.FloatTensor of size 1]

iteration 5900 avg_reward 20.83 loss 
 30867.1426
[torch.FloatTensor of size 1]

iteration 6000 avg_reward 17.92 loss 
 31609.8555
[torch.FloatTensor of size 1]

iteration 6100 avg_reward 16.18 loss 
 30465.4648
[torch.FloatTensor of size 1]

iteration 6200 avg_reward 16.12 loss 
 29238.0039
[torch.FloatTensor of size 1]

iteration 6300 avg_reward 16.27 loss 
 28308.9043
[torch.FloatTensor of size 1]

iteration 6400 avg_reward 17.14 loss 
 28045.8359
[torch.FloatTensor of size 1]

iteration 6500 avg_reward 16.34 loss 
 27553.5664
[torch.FloatTensor of size 1]

iteration 6600 avg_reward 16.26 loss 
 27109.7168
[torch.FloatTensor of size 1]

iteration 6700 avg_reward 17.23 loss 
 27034.0996
[torch.FloatTensor of size 1]

iteration 6800 avg_reward 17.4 loss 
 27244.5332
[torch.FloatTensor of size 1]

iteration 6900 avg_reward 18.05 loss 
 27870.1309
[torch.FloatTensor of size 1]

iteration 7000 avg_reward 19.07 loss 
 28869.4141
[torch.FloatTensor of size 1]

iteration 7100 avg_reward 19.0 loss 
 30187.4922
[torch.FloatTensor of size 1]

iteration 7200 avg_reward 16.69 loss 
 29733.4648
[torch.FloatTensor of size 1]

iteration 7300 avg_reward 18.07 loss 
 29646.8770
[torch.FloatTensor of size 1]

iteration 7400 avg_reward 17.75 loss 
 29960.9121
[torch.FloatTensor of size 1]

iteration 7500 avg_reward 18.48 loss 
 30239.9883
[torch.FloatTensor of size 1]

iteration 7600 avg_reward 17.92 loss 
 30316.0410
[torch.FloatTensor of size 1]

iteration 7700 avg_reward 18.0 loss 
 30165.7188
[torch.FloatTensor of size 1]

iteration 7800 avg_reward 18.91 loss 
 30699.4961
[torch.FloatTensor of size 1]

iteration 7900 avg_reward 21.16 loss 
 32308.3223
[torch.FloatTensor of size 1]

iteration 8000 avg_reward 21.16 loss 
 34603.8164
[torch.FloatTensor of size 1]

iteration 8100 avg_reward 22.81 loss 
 36899.7969
[torch.FloatTensor of size 1]

iteration 8200 avg_reward 29.2 loss 
 42718.0898
[torch.FloatTensor of size 1]

iteration 8300 avg_reward 28.67 loss 
 49769.7148
[torch.FloatTensor of size 1]

iteration 8400 avg_reward 25.07 loss 
 53072.9023
[torch.FloatTensor of size 1]

iteration 8500 avg_reward 24.22 loss 
 54257.6328
[torch.FloatTensor of size 1]

iteration 8600 avg_reward 20.42 loss 
 51573.7695
[torch.FloatTensor of size 1]

iteration 8700 avg_reward 21.06 loss 
 50053.2461
[torch.FloatTensor of size 1]

iteration 8800 avg_reward 24.33 loss 
 51605.5859
[torch.FloatTensor of size 1]

iteration 8900 avg_reward 21.83 loss 
 51387.4648
[torch.FloatTensor of size 1]

iteration 9000 avg_reward 21.81 loss 
 49163.2852
[torch.FloatTensor of size 1]

iteration 9100 avg_reward 32.56 loss 
 54883.9062
[torch.FloatTensor of size 1]

iteration 9200 avg_reward 59.18 loss 
 80368.0547
[torch.FloatTensor of size 1]

iteration 9300 avg_reward 60.62 loss 
1.00000e+05 *
  1.2572
[torch.FloatTensor of size 1]

iteration 9400 avg_reward 50.88 loss 
1.00000e+05 *
  1.4870
[torch.FloatTensor of size 1]

iteration 9500 avg_reward 53.53 loss 
1.00000e+05 *
  1.6450
[torch.FloatTensor of size 1]

iteration 9600 avg_reward 50.03 loss 
1.00000e+05 *
  1.7784
[torch.FloatTensor of size 1]

iteration 9700 avg_reward 49.42 loss 
1.00000e+05 *
  1.8862
[torch.FloatTensor of size 1]

iteration 9800 avg_reward 41.99 loss 
1.00000e+05 *
  1.9074
[torch.FloatTensor of size 1]

iteration 9900 avg_reward 36.76 loss 
1.00000e+05 *
  1.8388
[torch.FloatTensor of size 1]

iteration 10000 avg_reward 34.94 loss 
1.00000e+05 *
  1.7555
[torch.FloatTensor of size 1]

iteration 10100 avg_reward 45.71 loss 
1.00000e+05 *
  1.7324
[torch.FloatTensor of size 1]

iteration 10200 avg_reward 78.77 loss 
1.00000e+05 *
  2.1470
[torch.FloatTensor of size 1]

iteration 10300 avg_reward 68.83 loss 
1.00000e+05 *
  2.4959
[torch.FloatTensor of size 1]

iteration 10400 avg_reward 68.19 loss 
1.00000e+05 *
  2.7773
[torch.FloatTensor of size 1]

iteration 10500 avg_reward 59.9 loss 
1.00000e+05 *
  2.8991
[torch.FloatTensor of size 1]

iteration 10600 avg_reward 54.21 loss 
1.00000e+05 *
  2.9828
[torch.FloatTensor of size 1]

iteration 10700 avg_reward 39.65 loss 
1.00000e+05 *
  2.8707
[torch.FloatTensor of size 1]

iteration 10800 avg_reward 33.06 loss 
1.00000e+05 *
  2.6737
[torch.FloatTensor of size 1]

iteration 10900 avg_reward 24.66 loss 
1.00000e+05 *
  2.4457
[torch.FloatTensor of size 1]

iteration 11000 avg_reward 22.99 loss 
1.00000e+05 *
  2.2236
[torch.FloatTensor of size 1]

iteration 11100 avg_reward 16.05 loss 
1.00000e+05 *
  1.9939
[torch.FloatTensor of size 1]

iteration 11200 avg_reward 13.26 loss 
1.00000e+05 *
  1.7812
[torch.FloatTensor of size 1]

iteration 11300 avg_reward 11.59 loss 
1.00000e+05 *
  1.5882
[torch.FloatTensor of size 1]

iteration 11400 avg_reward 11.14 loss 
1.00000e+05 *
  1.4171
[torch.FloatTensor of size 1]

iteration 11500 avg_reward 10.59 loss 
1.00000e+05 *
  1.0900
[torch.FloatTensor of size 1]

iteration 11600 avg_reward 11.03 loss 
 88874.1484
[torch.FloatTensor of size 1]

iteration 11700 avg_reward 12.0 loss 
 79730.3047
[torch.FloatTensor of size 1]

iteration 11800 avg_reward 13.14 loss 
 74172.5234
[torch.FloatTensor of size 1]

iteration 11900 avg_reward 14.67 loss 
 69211.8672
[torch.FloatTensor of size 1]

iteration 12000 avg_reward 16.51 loss 
 63470.2891
[torch.FloatTensor of size 1]

iteration 12100 avg_reward 17.94 loss 
 58165.8438
[torch.FloatTensor of size 1]

iteration 12200 avg_reward 19.46 loss 
 53716.0352
[torch.FloatTensor of size 1]

iteration 12300 avg_reward 23.05 loss 
 51044.0391
[torch.FloatTensor of size 1]

iteration 12400 avg_reward 24.37 loss 
 51183.6719
[torch.FloatTensor of size 1]

iteration 12500 avg_reward 25.4 loss 
 51800.1133
[torch.FloatTensor of size 1]

iteration 12600 avg_reward 27.19 loss 
 53465.3242
[torch.FloatTensor of size 1]

iteration 12700 avg_reward 32.6 loss 
 57120.9492
[torch.FloatTensor of size 1]

iteration 12800 avg_reward 43.6 loss 
 69475.2188
[torch.FloatTensor of size 1]

iteration 12900 avg_reward 52.85 loss 
 92829.0781
[torch.FloatTensor of size 1]

iteration 13000 avg_reward 75.22 loss 
1.00000e+05 *
  1.5336
[torch.FloatTensor of size 1]

iteration 13100 avg_reward 67.05 loss 
1.00000e+05 *
  1.9642
[torch.FloatTensor of size 1]

iteration 13200 avg_reward 53.83 loss 
1.00000e+05 *
  1.8767
[torch.FloatTensor of size 1]

iteration 13300 avg_reward 59.19 loss 
1.00000e+05 *
  1.8442
[torch.FloatTensor of size 1]

iteration 13400 avg_reward 120.92 loss 
1.00000e+05 *
  2.4239
[torch.FloatTensor of size 1]

iteration 13500 avg_reward 101.11 loss 
1.00000e+05 *
  2.7372
[torch.FloatTensor of size 1]

iteration 13600 avg_reward 75.08 loss 
1.00000e+05 *
  2.1188
[torch.FloatTensor of size 1]

iteration 13700 avg_reward 122.97 loss 
1.00000e+05 *
  2.2529
[torch.FloatTensor of size 1]

iteration 13800 avg_reward 156.28 loss 
1.00000e+05 *
  3.3763
[torch.FloatTensor of size 1]

iteration 13900 avg_reward 189.5 loss 
1.00000e+05 *
  4.1920
[torch.FloatTensor of size 1]

iteration 14000 avg_reward 186.65 loss 
1.00000e+05 *
  5.3447
[torch.FloatTensor of size 1]

iteration 14100 avg_reward 184.4 loss 
 5.3712e+05
[torch.FloatTensor of size 1]

iteration 14200 avg_reward 145.73 loss 
1.00000e+05 *
  5.7751
[torch.FloatTensor of size 1]

iteration 14300 avg_reward 33.89 loss 
1.00000e+05 *
  3.5513
[torch.FloatTensor of size 1]

iteration 14400 avg_reward 135.03 loss 
1.00000e+05 *
  6.3506
[torch.FloatTensor of size 1]

iteration 14500 avg_reward 172.64 loss 
 5.8626e+05
[torch.FloatTensor of size 1]

iteration 14600 avg_reward 186.81 loss 
1.00000e+05 *
  5.8710
[torch.FloatTensor of size 1]

iteration 14700 avg_reward 196.35 loss 
 6.2321e+05
[torch.FloatTensor of size 1]
```

test_reinf_qs_to_a.py 796a9bc
```
[2017-09-18 02:06:58,706] Making new env: CartPole-v0
iteration 0 avg_reward 0.33 loss 33.21321374177933
iteration 100 avg_reward 13.78 loss 4047.9102981579526
iteration 200 avg_reward 9.9 loss 5806.175319439499
iteration 300 avg_reward 9.79 loss 6831.181566133164
iteration 400 avg_reward 9.9 loss 7359.374541618229
iteration 500 avg_reward 9.89 loss 7631.26329045184
iteration 600 avg_reward 9.86 loss 7911.5136107206345
iteration 700 avg_reward 15.79 loss 9228.981549067874
iteration 800 avg_reward 15.18 loss 11173.217043949804
iteration 900 avg_reward 14.68 loss 12024.706832421423
iteration 1000 avg_reward 15.92 loss 13704.424529085987
iteration 1100 avg_reward 15.69 loss 15637.032456686084
iteration 1200 avg_reward 16.91 loss 17530.220618936382
iteration 1300 avg_reward 17.72 loss 16442.354612561438
iteration 1400 avg_reward 17.97 loss 19540.47743723962
iteration 1500 avg_reward 19.1 loss 21412.958850755793
iteration 1600 avg_reward 21.65 loss 23093.895549669865
iteration 1700 avg_reward 20.68 loss 24530.27390587987
iteration 1800 avg_reward 30.23 loss 31736.255017701253
iteration 1900 avg_reward 23.74 loss 32374.298172996903
iteration 2000 avg_reward 28.13 loss 45529.431762100794
iteration 2100 avg_reward 25.43 loss 46228.529718953854
iteration 2200 avg_reward 24.9 loss 48756.742552725715
iteration 2300 avg_reward 23.89 loss 47878.13372052693
iteration 2400 avg_reward 29.43 loss 49826.92995607012
iteration 2500 avg_reward 26.67 loss 57035.413947721776
iteration 2600 avg_reward 30.94 loss 54709.574611283446
iteration 2700 avg_reward 31.95 loss 62153.22700492893
iteration 2800 avg_reward 36.97 loss 70291.36472847733
iteration 2900 avg_reward 35.9 loss 76254.39614007746
iteration 3000 avg_reward 24.42 loss 81065.5170526827
iteration 3100 avg_reward 30.77 loss 79536.417053821
iteration 3200 avg_reward 33.29 loss 80157.50414088981
iteration 3300 avg_reward 32.34 loss 86100.33789854764
iteration 3400 avg_reward 30.12 loss 88380.89313649813
iteration 3500 avg_reward 31.37 loss 86679.5778481311
iteration 3600 avg_reward 34.21 loss 88787.85102472585
iteration 3700 avg_reward 30.75 loss 87068.19585997934
iteration 3800 avg_reward 30.76 loss 89993.16858173693
iteration 3900 avg_reward 39.09 loss 91273.60342470297
iteration 4000 avg_reward 39.39 loss 84305.78482564734
iteration 4100 avg_reward 51.05 loss 85919.9955401768
iteration 4200 avg_reward 53.43 loss 99076.3771791305
iteration 4300 avg_reward 45.99 loss 126955.43852572922
iteration 4400 avg_reward 40.45 loss 130952.61830098655
iteration 4500 avg_reward 37.33 loss 134826.1849662094
iteration 4600 avg_reward 47.61 loss 129932.70969917024
iteration 4700 avg_reward 13.73 loss 113419.20083319007
iteration 4800 avg_reward 39.04 loss 96597.18044884429
iteration 4900 avg_reward 43.61 loss 106770.54043011735
iteration 5000 avg_reward 78.51 loss 101143.60909309228
iteration 5100 avg_reward 64.48 loss 153206.56042027054
iteration 5200 avg_reward 48.44 loss 179082.66699380352
iteration 5300 avg_reward 43.57 loss 166708.3195364129
iteration 5400 avg_reward 43.32 loss 169671.0916675232
iteration 5500 avg_reward 56.6 loss 182344.194376492
iteration 5600 avg_reward 80.96 loss 167832.1158780118
iteration 5700 avg_reward 58.38 loss 222869.99497148336
iteration 5800 avg_reward 62.22 loss 217731.61172731762
iteration 5900 avg_reward 70.16 loss 272848.4038172189
iteration 6000 avg_reward 85.0 loss 288101.839083062
iteration 6100 avg_reward 75.68 loss 331884.78133259993
iteration 6200 avg_reward 41.08 loss 354280.8263927291
iteration 6300 avg_reward 52.87 loss 377617.58717176045
iteration 6400 avg_reward 56.22 loss 379840.8196258145
iteration 6500 avg_reward 74.81 loss 321995.7301854283
iteration 6600 avg_reward 105.49 loss 259791.20340473065
iteration 6700 avg_reward 88.47 loss 359149.9639903552
iteration 6800 avg_reward 88.11 loss 312156.94460854254
iteration 6900 avg_reward 48.11 loss 219842.59086270453
iteration 7000 avg_reward 147.92 loss 168197.82834140526
iteration 7100 avg_reward 150.91 loss 290214.26846382447
iteration 7200 avg_reward 132.32 loss 413752.3365710253
iteration 7300 avg_reward 109.94 loss 319568.4806699076
iteration 7400 avg_reward 76.43 loss 119041.72470282977
iteration 7500 avg_reward 123.27 loss 138049.55718883988
iteration 7600 avg_reward 159.1 loss 187705.77868609462
iteration 7700 avg_reward 117.8 loss 438521.08929792745
iteration 7800 avg_reward 169.93 loss 273616.8395484203
iteration 7900 avg_reward 93.65 loss 750692.0907963566
iteration 8000 avg_reward 115.78 loss 876259.3585673008
iteration 8100 avg_reward 108.16 loss 973610.1179561047
iteration 8200 avg_reward 90.32 loss 949618.9740023669
iteration 8300 avg_reward 75.01 loss 841151.6334317354
iteration 8400 avg_reward 87.39 loss 874974.6174674793
iteration 8500 avg_reward 107.8 loss 866926.7034528791
iteration 8600 avg_reward 112.74 loss 813805.9340318064
iteration 8700 avg_reward 97.37 loss 664169.4246588377
iteration 8800 avg_reward 98.82 loss 735991.6777060574
iteration 8900 avg_reward 96.21 loss 596705.3917582589
iteration 9000 avg_reward 137.03 loss 512748.93924462027
iteration 9100 avg_reward 124.77 loss 671844.8747497143
iteration 9200 avg_reward 96.11 loss 545224.8473445136
iteration 9300 avg_reward 67.17 loss 738974.2490385985
iteration 9400 avg_reward 114.09 loss 725220.5987852237
iteration 9500 avg_reward 108.6 loss 1430124.694241533
iteration 9600 avg_reward 151.11 loss 1417628.8248314336
iteration 9700 avg_reward 103.56 loss 904023.0238435687
iteration 9800 avg_reward 129.94 loss 854330.5932447144
iteration 9900 avg_reward 128.47 loss 756393.8160893101
iteration 10000 avg_reward 116.77 loss 204697.21789817626
iteration 10100 avg_reward 170.8 loss 1283490.604635498
iteration 10200 avg_reward 126.79 loss 1351012.6417731538
iteration 10300 avg_reward 144.46 loss 1524948.2373585745
iteration 10400 avg_reward 157.04 loss 1572831.701821184
iteration 10500 avg_reward 139.65 loss 1591322.9305025854
iteration 10600 avg_reward 106.58 loss 1535287.5143627794
iteration 10700 avg_reward 177.49 loss 1618487.6636810254
iteration 10800 avg_reward 174.87 loss 1760778.3865141727
iteration 10900 avg_reward 138.4 loss 1823707.8985833144
iteration 11000 avg_reward 151.67 loss 1908152.3223435474
iteration 11100 avg_reward 148.3 loss 1785149.8341654507
iteration 11200 avg_reward 151.57 loss 1710649.2902250008
iteration 11300 avg_reward 170.27 loss 1555051.7050603698
iteration 11400 avg_reward 111.86 loss 1501825.8319209726
iteration 11500 avg_reward 172.75 loss 1140026.1465517688
iteration 11600 avg_reward 82.4 loss 1318301.1344017838
iteration 11700 avg_reward 129.81 loss 806106.2923983088
iteration 11800 avg_reward 110.03 loss 440314.91465512966
iteration 11900 avg_reward 156.72 loss 274143.0753150545
iteration 12000 avg_reward 165.92 loss 553693.3763004511
iteration 12100 avg_reward 185.18 loss 719542.6150923086
iteration 12200 avg_reward 182.11 loss 961337.9056542746
iteration 12300 avg_reward 189.98 loss 1031791.0396009476
iteration 12400 avg_reward 195.14 loss 1447984.0984640794
iteration 12500 avg_reward 171.0 loss 914543.2982249127
iteration 12600 avg_reward 184.32 loss 864845.7473777374
iteration 12700 avg_reward 164.85 loss 695551.7031885693
iteration 12800 avg_reward 186.51 loss 908553.4917483076
iteration 12900 avg_reward 182.49 loss 850998.4667638323
iteration 13000 avg_reward 187.79 loss 870051.4361791296
iteration 13100 avg_reward 190.33 loss 877149.6477515891
iteration 13200 avg_reward 196.21 loss 1284160.8360963815
iteration 13300 avg_reward 194.85 loss 1382738.9333476853
iteration 13400 avg_reward 191.37 loss 1478264.8417575837
iteration 13500 avg_reward 197.67 loss 2103462.636304339
iteration 13600 avg_reward 200.0 loss 2567486.527512188
iteration 13700 avg_reward 197.97 loss 3465874.432991078
iteration 13800 avg_reward 196.89 loss 3622746.104610271
iteration 13900 avg_reward 198.9 loss 4277161.661016781
```
